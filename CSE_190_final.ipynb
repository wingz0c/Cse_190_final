{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSE 190 Final Oroject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mido\n",
    "import numpy as np\n",
    "from mido import MidiFile, Message, MidiTrack\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Softmax\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(network_input, n_vocab):\n",
    "    \"\"\" Define constants \"\"\"\n",
    "    hidden_layers = 256\n",
    "    dropout = 0.4\n",
    "    \n",
    "    \"\"\" Initializing model \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    \"\"\" Adding LSTM Layers to Model \"\"\"\n",
    "    model.add(\n",
    "        Bidirectional(\n",
    "            LSTM(\n",
    "                hidden_layers,\n",
    "                dropout=dropout,\n",
    "                return_sequences=True\n",
    "            ),\n",
    "            input_shape=(network_input.shape[1], network_input.shape[2])\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        Bidirectional(\n",
    "            LSTM(\n",
    "                hidden_layers,\n",
    "                dropout=dropout,\n",
    "                return_sequences=True\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        Bidirectional(\n",
    "            LSTM(\n",
    "                hidden_layers,\n",
    "                dropout=dropout\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    \"\"\" Add other layers after LSTM \"\"\"\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(hidden_layers))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Lambda(lambda x: x / 0.6))\n",
    "    model.add(Softmax())\n",
    "    \n",
    "    \"\"\" Define the loss function for the model \"\"\"\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LUT for array indices storing note bits\n",
    "channels = [0,1,2,9]\n",
    "chanToArr = [0,1,2,0,0,0,0,0,0,3]\n",
    "\n",
    "def parse( input_midi ):\n",
    "    i = 1               # counter for each print statement\n",
    "    listo = []\n",
    "\n",
    "    prevChan = 0        # keeps track of previous channel to detect channel changes\n",
    "    chanIt = 0          # iterates to the next channel in the forced order 0->1->2->9\n",
    "    arr = [[0]*128]*4    # 12 notes each for channels(0,1,2,9) to keep track of continued notes\n",
    "\n",
    "    # insert MIDI file here\n",
    "    mid = MidiFile(input_midi) \n",
    "    temp = mido.merge_tracks(mid.tracks)\n",
    "\n",
    "    # processing MIDI file\n",
    "    for msg in temp:\n",
    "        # look for note changes\n",
    "        if(msg.type=='note_on'):\n",
    "\n",
    "            # check for a new channel\n",
    "            if(msg.channel != prevChan): \n",
    "                chanIt = chanIt + 1\n",
    "                if(chanIt == 4):\n",
    "                    chanIt = chanIt -4\n",
    "                    listo.append([0,0,0])\n",
    "                    i=i+1\n",
    "\n",
    "                # iterate chanIt to \"catch up\" to the next listed channel\n",
    "                while( channels[chanIt] != msg.channel):\n",
    "\n",
    "                    # continue notes if not turned off\n",
    "                    for a in range(len(arr[chanToArr[ channels[chanIt] ]])):\n",
    "                        if(arr[chanToArr[ channels[chanIt] ]][a]>0):\n",
    "                            listo[ arr[chanToArr[ channels[chanIt] ]][a] - 1 ][2] = listo[ arr[chanToArr[ channels[chanIt] ]][a] - 1 ][2] + 1\n",
    "                    chanIt = chanIt + 1\n",
    "                    if(chanIt == 4):\n",
    "                        chanIt = chanIt -4\n",
    "                        listo.append([0,0,0])\n",
    "                        i=i+1\n",
    "                    \n",
    "            # check if note_on event is on or off switch\n",
    "            if(msg.velocity==0):\n",
    "                noteSwitch = \"off\"\n",
    "                arr[chanToArr[msg.channel]][msg.note] = 0\n",
    "            else:\n",
    "                noteSwitch = \"on\"\n",
    "                arr[chanToArr[msg.channel]][msg.note] = i        \n",
    "                # print new note\n",
    "                listo.append([msg.note , msg.channel, 1])\n",
    "                i=i+1\n",
    "\n",
    "            # update prevChan for detection\n",
    "            prevChan = msg.channel\n",
    "\n",
    "    for t in range(len(listo)):\n",
    "        listo[t] = str(listo[t][0]) + \".\" + str(listo[t][1]) + \".\" + str(listo[t][2])\n",
    "        \n",
    "    return listo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes():\n",
    "    i=0\n",
    "    for file in glob.glob(\"multi-lstm-music/samples/small/*.mid\"):\n",
    "\n",
    "        print(\"Parsing %s\" % file)        \n",
    "        if(i==0):\n",
    "            notes = parse(file)\n",
    "            i=i+1\n",
    "        else:\n",
    "            notes = np.concatenate((notes, parse(file)))\n",
    "    \n",
    "    pickle.dump(notes, open('notes.p', 'wb'))\n",
    "    return notes\n",
    "\n",
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 4 \n",
    "\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "    \n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "    \n",
    "    n_patterns = len(network_input)\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "\n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "\n",
    "    network_output = to_categorical(network_output)\n",
    "    \n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing multi-lstm-music/samples/small\\084_DragonBuster_00_01TitleScreen.mid\n",
      "Parsing multi-lstm-music/samples/small\\084_DragonBuster_01_02RoundStart.mid\n",
      "Parsing multi-lstm-music/samples/small\\084_DragonBuster_02_03RengaBGM.mid\n",
      "Parsing multi-lstm-music/samples/small\\084_DragonBuster_03_04CatacombBGM.mid\n",
      "Parsing multi-lstm-music/samples/small\\084_DragonBuster_04_05LimestoneCaveBGM.mid\n",
      "Parsing multi-lstm-music/samples/small\\084_DragonBuster_05_06RoomGuardCombatBGM.mid\n",
      "Parsing multi-lstm-music/samples/small\\084_DragonBuster_06_07IwayamaDragonBGM.mid\n",
      "Parsing multi-lstm-music/samples/small\\084_DragonBuster_07_08PrincessAppears.mid\n",
      "Parsing multi-lstm-music/samples/small\\084_DragonBuster_08_09PrincessLoveSceneMusic.mid\n",
      "Parsing multi-lstm-music/samples/small\\084_DragonBuster_09_10GameOver.mid\n",
      "Parsing multi-lstm-music/samples/small\\084_DragonBuster_10_11Unknown.mid\n",
      "Parsing multi-lstm-music/samples/small\\086_DragonFighter_00_01Title.mid\n",
      "Parsing multi-lstm-music/samples/small\\086_DragonFighter_01_02TheFrozenBattleStage1.mid\n",
      "Parsing multi-lstm-music/samples/small\\086_DragonFighter_02_03Boss.mid\n",
      "Parsing multi-lstm-music/samples/small\\086_DragonFighter_03_04StageClear.mid\n",
      "Parsing multi-lstm-music/samples/small\\086_DragonFighter_04_05DontDisturbStage2.mid\n",
      "Parsing multi-lstm-music/samples/small\\086_DragonFighter_05_06IntotheDepthStage3.mid\n",
      "Parsing multi-lstm-music/samples/small\\086_DragonFighter_06_07CanyouChainUpStage4.mid\n",
      "Parsing multi-lstm-music/samples/small\\086_DragonFighter_07_08InitiveofaGhostStage5.mid\n",
      "Parsing multi-lstm-music/samples/small\\086_DragonFighter_08_09TheDragonFighterStage6.mid\n",
      "Parsing multi-lstm-music/samples/small\\086_DragonFighter_09_10FinalBoss.mid\n",
      "Parsing multi-lstm-music/samples/small\\086_DragonFighter_10_11Ending.mid\n",
      "Parsing multi-lstm-music/samples/small\\086_DragonFighter_11_12GameOver.mid\n",
      "Parsing multi-lstm-music/samples/small\\086_DragonFighter_12_13Continue.mid\n",
      "Parsing multi-lstm-music/samples/small\\087_DragonSpirit_TheNewLegend_00_01Start.mid\n",
      "Parsing multi-lstm-music/samples/small\\087_DragonSpirit_TheNewLegend_01_02DarkCastle1Area0Area91.mid\n",
      "Parsing multi-lstm-music/samples/small\\087_DragonSpirit_TheNewLegend_02_03ZawellGarudaLastBoss.mid\n",
      "Parsing multi-lstm-music/samples/small\\087_DragonSpirit_TheNewLegend_03_04LastSceneOpeningDemo.mid\n",
      "Parsing multi-lstm-music/samples/small\\087_DragonSpirit_TheNewLegend_04_05Opening.mid\n",
      "Parsing multi-lstm-music/samples/small\\087_DragonSpirit_TheNewLegend_05_06ThePaleozoicEraArea1.mid\n",
      "Parsing multi-lstm-music/samples/small\\087_DragonSpirit_TheNewLegend_06_07BossB.mid\n",
      "Parsing multi-lstm-music/samples/small\\087_DragonSpirit_TheNewLegend_07_08OmakeShaman.mid\n",
      "Parsing multi-lstm-music/samples/small\\087_DragonSpirit_TheNewLegend_08_09VolcanoArea2.mid\n",
      "Parsing multi-lstm-music/samples/small\\087_DragonSpirit_TheNewLegend_09_10JungleArea3.mid\n",
      "Parsing multi-lstm-music/samples/small\\087_DragonSpirit_TheNewLegend_10_11GraveYardArea4.mid\n",
      "Parsing multi-lstm-music/samples/small\\087_DragonSpirit_TheNewLegend_11_12CaveRoadArea5.mid\n",
      "Parsing multi-lstm-music/samples/small\\087_DragonSpirit_TheNewLegend_12_13GlaceirLandArea6.mid\n",
      "Parsing multi-lstm-music/samples/small\\087_DragonSpirit_TheNewLegend_13_14DeepSeaArea7.mid\n",
      "Parsing multi-lstm-music/samples/small\\087_DragonSpirit_TheNewLegend_14_15DarkQuartersArea8.mid\n",
      "Parsing multi-lstm-music/samples/small\\087_DragonSpirit_TheNewLegend_15_16DarkCastle3Area92.mid\n",
      "Parsing multi-lstm-music/samples/small\\087_DragonSpirit_TheNewLegend_16_17BossD.mid\n",
      "Parsing multi-lstm-music/samples/small\\087_DragonSpirit_TheNewLegend_17_18Ending.mid\n",
      "Parsing multi-lstm-music/samples/small\\087_DragonSpirit_TheNewLegend_18_19NameEntryRanks25Continue.mid\n",
      "['63.0.4' '58.1.4' '51.2.3' ... '0.0.0' '65.0.1' '63.0.1']\n",
      "Epoch 1/75\n",
      "1253/1253 [==============================] - 170s 136ms/step - loss: 5.0629\n",
      "Epoch 2/75\n",
      "1253/1253 [==============================] - 149s 119ms/step - loss: 4.5147\n",
      "Epoch 3/75\n",
      "1253/1253 [==============================] - 153s 122ms/step - loss: 4.2705\n",
      "Epoch 4/75\n",
      "1253/1253 [==============================] - 148s 118ms/step - loss: 4.1055\n",
      "Epoch 5/75\n",
      "1253/1253 [==============================] - 150s 120ms/step - loss: 3.9919\n",
      "Epoch 6/75\n",
      "1253/1253 [==============================] - 149s 119ms/step - loss: 3.9153\n",
      "Epoch 7/75\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 3.8477\n",
      "Epoch 8/75\n",
      "1253/1253 [==============================] - 147s 117ms/step - loss: 3.7929\n",
      "Epoch 9/75\n",
      "1253/1253 [==============================] - 153s 122ms/step - loss: 3.7491\n",
      "Epoch 10/75\n",
      "1253/1253 [==============================] - 156s 125ms/step - loss: 3.7209\n",
      "Epoch 11/75\n",
      "1253/1253 [==============================] - 149s 119ms/step - loss: 3.6847\n",
      "Epoch 12/75\n",
      "1253/1253 [==============================] - 148s 118ms/step - loss: 3.6482\n",
      "Epoch 13/75\n",
      "1253/1253 [==============================] - 150s 119ms/step - loss: 3.6237\n",
      "Epoch 14/75\n",
      "1253/1253 [==============================] - 152s 121ms/step - loss: 3.5977\n",
      "Epoch 15/75\n",
      "1253/1253 [==============================] - 152s 121ms/step - loss: 3.5697\n",
      "Epoch 16/75\n",
      "1253/1253 [==============================] - 158s 126ms/step - loss: 3.5482\n",
      "Epoch 17/75\n",
      "1253/1253 [==============================] - 149s 119ms/step - loss: 3.5231\n",
      "Epoch 18/75\n",
      "1253/1253 [==============================] - 148s 118ms/step - loss: 3.5044\n",
      "Epoch 19/75\n",
      "1253/1253 [==============================] - 153s 122ms/step - loss: 3.4782\n",
      "Epoch 20/75\n",
      "1253/1253 [==============================] - 153s 122ms/step - loss: 3.4737\n",
      "Epoch 21/75\n",
      "1253/1253 [==============================] - 152s 121ms/step - loss: 3.4664\n",
      "Epoch 22/75\n",
      "1253/1253 [==============================] - 151s 121ms/step - loss: 3.4349\n",
      "Epoch 23/75\n",
      "1253/1253 [==============================] - 151s 121ms/step - loss: 3.4177\n",
      "Epoch 24/75\n",
      "1253/1253 [==============================] - 150s 119ms/step - loss: 3.4032\n",
      "Epoch 25/75\n",
      "1253/1253 [==============================] - 151s 120ms/step - loss: 3.4035\n",
      "Epoch 26/75\n",
      "1253/1253 [==============================] - 151s 120ms/step - loss: 3.3646\n",
      "Epoch 27/75\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 3.3705\n",
      "Epoch 28/75\n",
      "1253/1253 [==============================] - 162s 130ms/step - loss: 3.3576\n",
      "Epoch 29/75\n",
      "1253/1253 [==============================] - 172s 137ms/step - loss: 3.3491\n",
      "Epoch 30/75\n",
      "1253/1253 [==============================] - 159s 127ms/step - loss: 3.3377\n",
      "Epoch 31/75\n",
      "1253/1253 [==============================] - 167s 133ms/step - loss: 3.3306\n",
      "Epoch 32/75\n",
      "1253/1253 [==============================] - 160s 128ms/step - loss: 3.3221\n",
      "Epoch 33/75\n",
      "1253/1253 [==============================] - 167s 133ms/step - loss: 3.2949\n",
      "Epoch 34/75\n",
      "1253/1253 [==============================] - 160s 128ms/step - loss: 3.2926\n",
      "Epoch 35/75\n",
      "1253/1253 [==============================] - 151s 120ms/step - loss: 3.2867\n",
      "Epoch 36/75\n",
      "1253/1253 [==============================] - 146s 116ms/step - loss: 3.2651\n",
      "Epoch 37/75\n",
      "1253/1253 [==============================] - 145s 116ms/step - loss: 3.2803\n",
      "Epoch 38/75\n",
      "1253/1253 [==============================] - 146s 117ms/step - loss: 3.2706\n",
      "Epoch 39/75\n",
      "1253/1253 [==============================] - 147s 118ms/step - loss: 3.2601\n",
      "Epoch 40/75\n",
      "1253/1253 [==============================] - 146s 117ms/step - loss: 3.2443\n",
      "Epoch 41/75\n",
      "1253/1253 [==============================] - 146s 116ms/step - loss: 3.2277\n",
      "Epoch 42/75\n",
      "1253/1253 [==============================] - 149s 119ms/step - loss: 3.2264\n",
      "Epoch 43/75\n",
      "1253/1253 [==============================] - 151s 121ms/step - loss: 3.2115\n",
      "Epoch 44/75\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 3.2218\n",
      "Epoch 45/75\n",
      "1253/1253 [==============================] - 152s 121ms/step - loss: 3.1973\n",
      "Epoch 46/75\n",
      "1253/1253 [==============================] - 151s 121ms/step - loss: 3.2062\n",
      "Epoch 47/75\n",
      "1253/1253 [==============================] - 155s 124ms/step - loss: 3.1999\n",
      "Epoch 48/75\n",
      "1253/1253 [==============================] - 155s 124ms/step - loss: 3.1827\n",
      "Epoch 49/75\n",
      "1253/1253 [==============================] - 151s 121ms/step - loss: 3.1951\n",
      "Epoch 50/75\n",
      "1253/1253 [==============================] - 152s 122ms/step - loss: 3.1762\n",
      "Epoch 51/75\n",
      "1253/1253 [==============================] - 156s 124ms/step - loss: 3.1769\n",
      "Epoch 52/75\n",
      "1253/1253 [==============================] - 151s 120ms/step - loss: 3.1777\n",
      "Epoch 53/75\n",
      "1253/1253 [==============================] - 150s 120ms/step - loss: 3.1556\n",
      "Epoch 54/75\n",
      "1253/1253 [==============================] - 150s 120ms/step - loss: 3.1528\n",
      "Epoch 55/75\n",
      "1253/1253 [==============================] - 150s 120ms/step - loss: 3.1432\n",
      "Epoch 56/75\n",
      "1253/1253 [==============================] - 152s 122ms/step - loss: 3.1461\n",
      "Epoch 57/75\n",
      "1253/1253 [==============================] - 156s 124ms/step - loss: 3.1392\n",
      "Epoch 58/75\n",
      "1253/1253 [==============================] - 156s 124ms/step - loss: 3.1223\n",
      "Epoch 59/75\n",
      "1253/1253 [==============================] - 156s 125ms/step - loss: 3.1254\n",
      "Epoch 60/75\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 3.1172\n",
      "Epoch 61/75\n",
      "1253/1253 [==============================] - 167s 133ms/step - loss: 3.1177\n",
      "Epoch 62/75\n",
      "1253/1253 [==============================] - 165s 131ms/step - loss: 3.1172\n",
      "Epoch 63/75\n",
      "1253/1253 [==============================] - 169s 135ms/step - loss: 3.1052\n",
      "Epoch 64/75\n",
      "1253/1253 [==============================] - 168s 134ms/step - loss: 3.1044\n",
      "Epoch 65/75\n",
      "1253/1253 [==============================] - 160s 128ms/step - loss: 3.1081\n",
      "Epoch 66/75\n",
      "1253/1253 [==============================] - 159s 127ms/step - loss: 3.1102\n",
      "Epoch 67/75\n",
      "1253/1253 [==============================] - 157s 126ms/step - loss: 3.0871\n",
      "Epoch 68/75\n",
      "1253/1253 [==============================] - 165s 132ms/step - loss: 3.0807\n",
      "Epoch 69/75\n",
      "1253/1253 [==============================] - 167s 133ms/step - loss: 3.0752\n",
      "Epoch 70/75\n",
      "1253/1253 [==============================] - 159s 127ms/step - loss: 3.0733\n",
      "Epoch 71/75\n",
      "1253/1253 [==============================] - 156s 124ms/step - loss: 3.0713\n",
      "Epoch 72/75\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 3.0708\n",
      "Epoch 73/75\n",
      "1253/1253 [==============================] - 160s 127ms/step - loss: 3.0493\n",
      "Epoch 74/75\n",
      "1253/1253 [==============================] - 159s 127ms/step - loss: 3.0579\n",
      "Epoch 75/75\n",
      "1253/1253 [==============================] - 159s 127ms/step - loss: 3.0646\n"
     ]
    }
   ],
   "source": [
    "def train_network():\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    notes = get_notes()\n",
    "    n_vocab = len(set(notes))\n",
    "    \n",
    "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "    \n",
    "    model = create_network(network_input, n_vocab)\n",
    " \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        \"weights2-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\",\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    # Your line of code here\n",
    "    model.fit(network_input, network_output, batch_size=32, epochs=75, verbose=1, callbacks=callbacks_list)\n",
    "\n",
    "train_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences_prediction(notes, pitchnames, n_vocab):\n",
    "\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "    sequence_length = 4\n",
    "    network_input = []\n",
    "    output = []\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    normalized_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    normalized_input = normalized_input / float(n_vocab)\n",
    "\n",
    "    return (network_input, normalized_input)\n",
    "\n",
    "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # Starts the melody by picking a random sequence from the input as a starting point\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "\n",
    "\n",
    "    for note_index in range(1000):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        ### Copy the line below from your above implementation.\n",
    "        prediction =   model.predict( prediction_input )\n",
    "        \n",
    "        sum = 0\n",
    "        i = 0\n",
    "        \n",
    "        for a in prediction[0]:\n",
    "            sum = sum + a\n",
    "        x = random.random() * sum\n",
    "        \n",
    "        for a in prediction[0]:\n",
    "            x = x - a\n",
    "            if(x < 0):\n",
    "                break\n",
    "            i = i+1\n",
    "\n",
    "        index = i\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "        \n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    notes = pickle.load(open('notes.p', 'rb'))\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    n_vocab = len(set(notes))\n",
    "\n",
    "    network_input, normalized_input = prepare_sequences_prediction(notes, pitchnames, n_vocab)\n",
    "    model = create_network(normalized_input, n_vocab)\n",
    "    \n",
    "    ### Add a line to load the weights here\n",
    "    \n",
    "    model.load_weights(\"weights2-improvement-73-3.0493-bigger.hdf5\")\n",
    "    \n",
    "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
    "    create_midi(prediction_output)\n",
    "    \n",
    "def create_midi(prediction_output):\n",
    "    i = 0\n",
    "    for a in prediction_output:\n",
    "        prediction_output[i] = [int(x) for x in a.split('.')]\n",
    "        i=i+1\n",
    "    \n",
    "    t0notes = []\n",
    "    t1notes = []\n",
    "    t2notes = []\n",
    "    t9notes = []\n",
    "    \n",
    "    for a in prediction_output:\n",
    "        if(a[2] == 0):\n",
    "            pass\n",
    "        else:       \n",
    "            if( a[1] == 0 ):\n",
    "                t0notes.append([a[0],a[2]])\n",
    "            elif( a[1] == 1 ):\n",
    "                t1notes.append([a[0],a[2]])\n",
    "            elif( a[1] == 2 ):\n",
    "                t2notes.append([a[0],a[2]])\n",
    "            elif( a[1] == 9 ):\n",
    "                t9notes.append([a[0],a[2]])\n",
    "                                    \n",
    "#     print(t0notes)\n",
    "#     print(t1notes)\n",
    "#     print(t2notes)\n",
    "#     print(t9notes)\n",
    "    \n",
    "    \n",
    "    mid = MidiFile()\n",
    "    mTrack = MidiTrack()\n",
    "    track0 = MidiTrack()\n",
    "    track1 = MidiTrack()\n",
    "    track2 = MidiTrack()\n",
    "    track9 = MidiTrack()\n",
    "    mid.tracks.append(mTrack)\n",
    "    mid.tracks.append(track0)\n",
    "    mid.tracks.append(track1)\n",
    "    mid.tracks.append(track2)\n",
    "    mid.tracks.append(track9)\n",
    "\n",
    "    track0.append(Message('program_change', channel=0, program=80, time=0))\n",
    "    track1.append(Message('program_change', channel=1, program=81, time=0))\n",
    "    track2.append(Message('program_change', channel=2, program=38, time=0))\n",
    "    track9.append(Message('program_change', channel=9, program=121, time=0))\n",
    "\n",
    "    for a in t0notes:\n",
    "        track0.append(Message('note_on', channel=0, note=a[0], time=a[1]*100))\n",
    "        track0.append(Message('note_on', channel=0, note=a[0], velocity=0))\n",
    "    for a in t1notes:\n",
    "        track1.append(Message('note_on', channel=1, note=a[0], time=a[1]*100))\n",
    "        track1.append(Message('note_on', channel=1, note=a[0], velocity=0))\n",
    "    for a in t2notes:\n",
    "        track2.append(Message('note_on', channel=2, note=a[0], time=a[1]*100))\n",
    "        track2.append(Message('note_on', channel=2, note=a[0], velocity=0))\n",
    "    for a in t9notes:\n",
    "        track9.append(Message('note_on', channel=9, note=a[0], time=a[1]*100))\n",
    "        track9.append(Message('note_on', channel=9, note=a[0], velocity=0))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    mid.save('output.mid')\n",
    "\n",
    "generate()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
